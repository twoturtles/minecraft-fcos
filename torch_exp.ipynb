{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1604dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchvision.models.detection import fcos\n",
    "from torchvision.transforms import v2 as v2\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import bb\n",
    "import models\n",
    "import tt\n",
    "\n",
    "LOG = logging.getLogger(__name__)\n",
    "tt.logging_init()\n",
    "\n",
    "SEED = 325\n",
    "tt.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613356d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path.home() / \"src/data\"\n",
    "mc_data_path = data_path / \"minecraft/info.json\"\n",
    "dset = bb.Dataset.load(mc_data_path)\n",
    "torch_root = data_path / \"torchvision\"\n",
    "ckpt_root = data_path / \"checkpoints\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b4896",
   "metadata": {},
   "source": [
    "# bb.TorchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdset = bb.TorchDataset(data_path / \"minecraft\")\n",
    "tdset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(tdset, batch_size=8, collate_fn=bb.TorchDataset.collate_fn)\n",
    "images, targets = next(iter(loader))\n",
    "result = tv.utils.make_grid(\n",
    "    [bb.torch_plot_bb(img, target, tdset.categories) for img, target in zip(images, targets)], nrow=2\n",
    ")\n",
    "v2.functional.to_pil_image(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = tdset[10]\n",
    "categories = tdset.dset.categories\n",
    "label_names = [categories[label.item()] for label in target[\"labels\"]]\n",
    "result = bb.torch_plot_bb(img, target, tdset.categories)\n",
    "v2.functional.to_pil_image(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc0e2f9",
   "metadata": {},
   "source": [
    "# Minecraft COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ede53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert internal format to coco\n",
    "dset = bb.Dataset.load(mc_data_path)\n",
    "dset.to_coco(data_path / \"coco/minecraft\", add_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a42052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.pytorch.org/vision/main/auto_examples/transforms/plot_transforms_e2e.html\n",
    "\n",
    "IMAGES_PATH = data_path / \"coco/minecraft/images\"\n",
    "ANNOTATIONS_PATH = data_path / \"coco/minecraft/annotations.json\"\n",
    "coco_dataset = tv.datasets.wrap_dataset_for_transforms_v2(\n",
    "    # The transforms can be v2 since they're handled by the wrapper.\n",
    "    tv.datasets.CocoDetection(IMAGES_PATH, ANNOTATIONS_PATH, transforms=v2.ToImage())\n",
    ")\n",
    "\n",
    "coco_categories = {\n",
    "    cat[\"id\"]: cat[\"name\"] for cat in coco_dataset.coco.loadCats(coco_dataset.coco.getCatIds())\n",
    "}\n",
    "print(coco_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = coco_dataset[0]\n",
    "label_names = [coco_categories[label.item()] for label in target[\"labels\"]]\n",
    "print(target)\n",
    "print(label_names)\n",
    "v2.ToPILImage()(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d333f",
   "metadata": {},
   "source": [
    "# MCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a797955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "n_train=346, n_valid=62\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "TRAIN_PCT = .85\n",
    "\n",
    "ckpt_file = str(ckpt_root / \"checkpoint.pt\")\n",
    "mcd_root = data_path / \"coco/minecraft\"\n",
    "mcd = bb.MCDataset(mcd_root)\n",
    "train_dset, valid_dset = tt.split1(mcd, TRAIN_PCT, SEED)\n",
    "# bb.plot_bb_grid(images, targets, mcd.categories)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=bb.MCDataset.collate_fn,\n",
    "    shuffle=True,\n",
    "    generator=torch.Generator().manual_seed(SEED),\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=bb.MCDataset.collate_fn,\n",
    ")\n",
    "\n",
    "print(f\"n_train={len(train_dset)}, n_valid={len(valid_dset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mc-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
